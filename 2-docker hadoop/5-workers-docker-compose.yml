version: '3.8'
services:
  master:
    image: jfriasl-spark-hadoop
    hostname: master
    container_name: spark-master
    user: "1000:1000"
    command: /opt/spark/bin/start-master.sh  
    environment:
      MASTER: spark://master:7077
      SPARK_CONF_DIR: /conf
      SPARK_PUBLIC_DNS: master
      HADOOP_CONF_DIR: /opt/hadoop/etc/hadoop
      YARN_CONF_DIR: /opt/hadoop/etc/hadoop
    ports:
      - 4040:4040    
      - 7077:7077    
      - 8080:8080    
      - 9870:9870    
      - 9000:9000    
    volumes:
      - ./conf/master:/conf:rw
      - ./data:/data:rw
      - ./workspace-shared:/home/spark/workspace/shared:rw
      - /mnt/volume:/mnt/volume:rw
      - /media/hadoop/master:/opt/hadoop/dfs/name:rw
      - /media/hadoop/logs:/opt/hadoop/logs:rw


  worker1:
    image: jfriasl-spark-hadoop
    hostname: worker1    
    container_name: spark-worker-1
    user: "1000:1000"
    command: /opt/spark/bin/start-worker.sh  
    environment:
      SPARK_CONF_DIR: /conf
      SPARK_WORKER_CORES: 4
      SPARK_WORKER_MEMORY: 8g
      SPARK_WORKER_WEBUI_PORT: 8081
      SPARK_WORKER_PORT: 8881
      #SPARK_PUBLIC_DNS: worker1
      HADOOP_CONF_DIR: /opt/hadoop/etc/hadoop
      YARN_CONF_DIR: /opt/hadoop/etc/hadoop
    depends_on:
      - master
    ports:
      - 8081:8081    
      - 50075:50075  
    volumes:
      - ./conf/worker:/conf:rw
      - ./data:/data:rw
      - ./workspace-shared:/home/spark/workspace/shared:rw
      - /mnt/volume:/mnt/volume:rw
      - /media/hadoop/worker1:/opt/hadoop/dfs/data:rw
      - /media/hadoop/logs:/opt/hadoop/logs:rw

  worker2:
    image: jfriasl-spark-hadoop
    hostname: worker2
    container_name: spark-worker-2
    user: "1000:1000"
    command: /opt/spark/bin/start-worker.sh  
    environment:
      SPARK_CONF_DIR: /conf
      SPARK_WORKER_CORES: 4
      SPARK_WORKER_MEMORY: 8g
      SPARK_WORKER_WEBUI_PORT: 8082
      SPARK_WORKER_PORT: 8882
      #SPARK_PUBLIC_DNS: worker2
      HADOOP_CONF_DIR: /opt/hadoop/etc/hadoop
      YARN_CONF_DIR: /opt/hadoop/etc/hadoop
    depends_on:
      - master
    ports:
      - 8082:8082
      - 50076:50075
    volumes:
      - ./conf/worker:/conf:rw
      - ./data:/data:rw
      - ./workspace-shared:/home/spark/workspace/shared:rw
      - /mnt/volume:/mnt/volume:rw
      - /media/hadoop/worker2:/opt/hadoop/dfs/data:rw
      - /media/hadoop/logs:/opt/hadoop/logs:rw    

  worker3:
    image: jfriasl-spark-hadoop
    hostname: worker3
    container_name: spark-worker-3
    user: "1000:1000"
    command: /opt/spark/bin/start-worker.sh 
    environment:
      SPARK_CONF_DIR: /conf
      SPARK_WORKER_CORES: 4
      SPARK_WORKER_MEMORY: 8g
      SPARK_WORKER_WEBUI_PORT: 8083
      SPARK_WORKER_PORT: 8883
      #SPARK_PUBLIC_DNS: worker3
      HADOOP_CONF_DIR: /opt/hadoop/etc/hadoop
      YARN_CONF_DIR: /opt/hadoop/etc/hadoop
    depends_on:
      - master
    ports:
      - 8083:8083
      - 50077:50075
    volumes:
      - ./conf/worker:/conf:rw
      - ./data:/data:rw
      - ./workspace-shared:/home/spark/workspace/shared:rw
      - /mnt/volume:/mnt/volume:rw
      - /media/hadoop/worker3:/opt/hadoop/dfs/data:rw
      - /media/hadoop/logs:/opt/hadoop/logs:rw       

  worker4:
    image: jfriasl-spark-hadoop
    hostname: worker4
    container_name: spark-worker-4
    user: "1000:1000"
    command: /opt/spark/bin/start-worker.sh 
    environment:
      SPARK_CONF_DIR: /conf
      SPARK_WORKER_CORES: 4
      SPARK_WORKER_MEMORY: 8g
      SPARK_WORKER_WEBUI_PORT: 8084
      SPARK_WORKER_PORT: 8884
      #SPARK_PUBLIC_DNS: worker4
      HADOOP_CONF_DIR: /opt/hadoop/etc/hadoop
      YARN_CONF_DIR: /opt/hadoop/etc/hadoop
    depends_on:
      - master
    ports:
      - 8084:8084      
      - 50078:50075
    volumes:
      - ./conf/worker:/conf:rw
      - ./data:/data:rw
      - ./workspace-shared:/home/spark/workspace/shared:rw
      - /mnt/volume:/mnt/volume:rw
      - /media/hadoop/worker4:/opt/hadoop/dfs/data:rw
      - /media/hadoop/logs:/opt/hadoop/logs:rw   

  worker5:
    image: jfriasl-spark-hadoop
    hostname: worker5
    container_name: spark-worker-5
    user: "1000:1000"
    command: /opt/spark/bin/start-worker.sh 
    environment:
      SPARK_CONF_DIR: /conf
      SPARK_WORKER_CORES: 4
      SPARK_WORKER_MEMORY: 8g
      SPARK_WORKER_WEBUI_PORT: 8085
      SPARK_WORKER_PORT: 8885
      #SPARK_PUBLIC_DNS: worker5
      HADOOP_CONF_DIR: /opt/hadoop/etc/hadoop
      YARN_CONF_DIR: /opt/hadoop/etc/hadoop
    depends_on:
      - master
    ports:
      - 8085:8085
      - 50079:50075
    volumes:
      - ./conf/worker:/conf:rw
      - ./data:/data:rw
      - ./workspace-shared:/home/spark/workspace/shared:rw
      - /mnt/volume:/mnt/volume:rw
      - /media/hadoop/worker5:/opt/hadoop/dfs/data:rw
      - /media/hadoop/logs:/opt/hadoop/logs:rw         

  jupyter:
    image: jfriasl-spark-hadoop
    container_name: spark-jupyter
    user: "1000:1000"
    command: >
      bash -c "
      exec jupyter-lab --ip=0.0.0.0 --port=8888 --allow-root \
          --no-browser \
          --notebook-dir='/mnt/volume' \ 
          --LabApp.token='' \
          --LabApp.allow_origin='*'
      "
    ports:
      - 10000:8888 
    volumes:
      - ./workspace-shared:/home/spark/workspace:rw
      - ./notebooks:/home/spark/notebooks:rw
      - ./data:/data:rw
      - ./scripts:/opt/scripts:ro
      - /mnt/volume:/mnt/volume:rw
    depends_on:
      - master
    environment:
      SPARK_CONF_DIR: /conf
      HADOOP_CONF_DIR: /opt/hadoop/etc/hadoop
      YARN_CONF_DIR: /opt/hadoop/etc/hadoop
      PYSPARK_PYTHON: python3